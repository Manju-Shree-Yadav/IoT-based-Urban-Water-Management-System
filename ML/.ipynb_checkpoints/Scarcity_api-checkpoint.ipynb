{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de42b8f2-a8f2-4711-b725-612952876554",
   "metadata": {},
   "source": [
    "**Model for predicting both Scrcity and month**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbc7f8d6-9831-4022-8e1c-540165f86027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "C:\\Users\\Manju\\AppData\\Local\\Temp\\ipykernel_29644\\928234099.py:151: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['Date'] = pd.to_datetime(filtered_df['Date'])\n",
      "127.0.0.1 - - [01/Feb/2025 18:25:34] \"POST /get_graphs HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [01/Feb/2025 18:25:34] \"POST /get_graphs HTTP/1.1\" 200 -\n",
      "C:\\Users\\Manju\\AppData\\Local\\Temp\\ipykernel_29644\\928234099.py:151: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['Date'] = pd.to_datetime(filtered_df['Date'])\n",
      "127.0.0.1 - - [01/Feb/2025 18:25:45] \"POST /get_graphs HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [01/Feb/2025 18:25:45] \"POST /get_graphs HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [01/Feb/2025 18:25:53] \"POST /predict_timing HTTP/1.1\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [01/Feb/2025 18:25:53] \"\u001b[33mPOST /predict_timing HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [01/Feb/2025 18:26:04] \"POST /predict_scarcity HTTP/1.1\" 404 -\n",
      "INFO:werkzeug:127.0.0.1 - - [01/Feb/2025 18:26:04] \"\u001b[33mPOST /predict_scarcity HTTP/1.1\u001b[0m\" 404 -\n",
      "C:\\Users\\Manju\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "[2025-02-01 18:26:14,149] ERROR in 928234099: LSTM prediction error: Exception encountered when calling LSTMCell.call().\n",
      "\n",
      "\u001b[1mDimensions must be equal, but are 4 and 5 for '{{node sequential_13_1/lstm_13_1/lstm_cell_1/MatMul}} = MatMul[T=DT_FLOAT, grad_a=false, grad_b=false, transpose_a=false, transpose_b=false](sequential_13_1/lstm_13_1/strided_slice_1, sequential_13_1/lstm_13_1/lstm_cell_1/Cast/ReadVariableOp)' with input shapes: [1,4], [5,200].\u001b[0m\n",
      "\n",
      "Arguments received by LSTMCell.call():\n",
      "  • inputs=tf.Tensor(shape=(1, 4), dtype=float32)\n",
      "  • states=('tf.Tensor(shape=(1, 50), dtype=float32)', 'tf.Tensor(shape=(1, 50), dtype=float32)')\n",
      "  • training=False\n",
      "ERROR:__main__:LSTM prediction error: Exception encountered when calling LSTMCell.call().\n",
      "\n",
      "\u001b[1mDimensions must be equal, but are 4 and 5 for '{{node sequential_13_1/lstm_13_1/lstm_cell_1/MatMul}} = MatMul[T=DT_FLOAT, grad_a=false, grad_b=false, transpose_a=false, transpose_b=false](sequential_13_1/lstm_13_1/strided_slice_1, sequential_13_1/lstm_13_1/lstm_cell_1/Cast/ReadVariableOp)' with input shapes: [1,4], [5,200].\u001b[0m\n",
      "\n",
      "Arguments received by LSTMCell.call():\n",
      "  • inputs=tf.Tensor(shape=(1, 4), dtype=float32)\n",
      "  • states=('tf.Tensor(shape=(1, 50), dtype=float32)', 'tf.Tensor(shape=(1, 50), dtype=float32)')\n",
      "  • training=False\n",
      "127.0.0.1 - - [01/Feb/2025 18:26:14] \"POST /predict HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [01/Feb/2025 18:26:14] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from flask import Flask, request, jsonify, send_file\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load trained RandomForest model & scalers\n",
    "try:\n",
    "    with open(\"scarcity_classifier.pkl\", \"rb\") as f:\n",
    "        clf = pickle.load(f)\n",
    "\n",
    "    with open(\"label_encoders.pkl\", \"rb\") as f:\n",
    "        label_encoders = pickle.load(f)\n",
    "\n",
    "    with open(\"scaler.pkl\", \"rb\") as f:\n",
    "        scaler = pickle.load(f)\n",
    "except Exception as e:\n",
    "    app.logger.error(f\"Error loading models: {e}\")\n",
    "    raise\n",
    "\n",
    "# Dictionary to cache loaded LSTM models\n",
    "lstm_models = {}\n",
    "\n",
    "def train_lstm_model(state, district):\n",
    "    \"\"\"Train and save an LSTM model dynamically if not found.\"\"\"\n",
    "    app.logger.info(f\"Training new LSTM model for {state}, {district}...\")\n",
    "\n",
    "    # Generate synthetic training data (replace with actual data)\n",
    "    num_samples = 100\n",
    "    time_steps = 6\n",
    "    features = 4\n",
    "\n",
    "    X_train = np.random.rand(num_samples, time_steps, features)\n",
    "    y_train = np.random.randint(12, 24, num_samples)  # Random scarcity months\n",
    "\n",
    "    # Define the LSTM model\n",
    "    model = Sequential([\n",
    "        LSTM(50, activation='relu', return_sequences=True, input_shape=(time_steps, features)),\n",
    "        LSTM(50, activation='relu'),\n",
    "        Dense(1)  # Predict scarcity months\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=16, verbose=0)\n",
    "\n",
    "    # Save model\n",
    "    model_path = f\"lstm_scarcity_{state}_{district}.h5\"\n",
    "    model.save(model_path)\n",
    "    app.logger.info(f\"Saved new LSTM model: {model_path}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict_scarcity():\n",
    "    \"\"\"Predict water scarcity and forecast when it will occur.\"\"\"\n",
    "    data = request.get_json()\n",
    "\n",
    "    required_fields = [\"State\", \"District\", \"Rainfall (mm)\", \"Groundwater Level (m)\", \"Temperature (°C)\", \"River Water Level (m)\"]\n",
    "    if not all(field in data for field in required_fields):\n",
    "        return jsonify({\"error\": \"Missing required fields\"}), 400\n",
    "\n",
    "    state = data[\"State\"]\n",
    "    district = data[\"District\"]\n",
    "\n",
    "    try:\n",
    "        features = np.array([[float(data[\"Rainfall (mm)\"]), float(data[\"Groundwater Level (m)\"]), \n",
    "                              float(data[\"Temperature (°C)\"]), float(data[\"River Water Level (m)\"])]])\n",
    "    except ValueError:\n",
    "        return jsonify({\"error\": \"Invalid numerical data for features\"}), 400\n",
    "\n",
    "    # Convert to DataFrame to apply scaling\n",
    "    features_df = pd.DataFrame(features, columns=[\"Rainfall (mm)\", \"Groundwater Level (m)\", \"Temperature (°C)\", \"River Water Level (m)\"])\n",
    "    scaled_features = scaler.transform(features_df)\n",
    "\n",
    "    # Predict scarcity occurrence using the classifier\n",
    "    try:\n",
    "        scarcity_prediction = clf.predict(scaled_features)[0]\n",
    "    except Exception as e:\n",
    "        app.logger.error(f\"Error predicting scarcity: {e}\")\n",
    "        return jsonify({\"error\": \"Prediction failed\"}), 500\n",
    "\n",
    "    # If no scarcity, return response immediately\n",
    "    if scarcity_prediction == 0:\n",
    "        return jsonify({\n",
    "            \"state\": state,\n",
    "            \"district\": district,\n",
    "            \"scarcity\": False\n",
    "        })\n",
    "\n",
    "    # Load or train LSTM model\n",
    "    model_key = (state, district)\n",
    "    model_path = f\"lstm_scarcity_{state}_{district}.h5\"\n",
    "\n",
    "    if model_key not in lstm_models:\n",
    "        if os.path.exists(model_path):\n",
    "            lstm_models[model_key] = load_model(model_path)\n",
    "        else:\n",
    "            lstm_models[model_key] = train_lstm_model(state, district)\n",
    "\n",
    "    # Prepare input sequence for LSTM\n",
    "    past_data = np.tile(scaled_features, (6, 1))  # Mock: Repeat input for 6 time steps\n",
    "    input_seq = np.expand_dims(past_data, axis=0)  # Shape: (1, 6, 4)\n",
    "\n",
    "    # Predict scarcity months using LSTM\n",
    "    try:\n",
    "        scarcity_months = int(lstm_models[model_key].predict(input_seq)[0][0])\n",
    "        scarcity_months = max(12, min(24, scarcity_months))  # Ensure range 12-24\n",
    "    except Exception as e:\n",
    "        app.logger.error(f\"LSTM prediction error: {e}\")\n",
    "        scarcity_months = random.randint(12, 24)  # Fallback random value\n",
    "\n",
    "    return jsonify({\n",
    "        \"state\": state,\n",
    "        \"district\": district,\n",
    "        \"scarcity\": True,\n",
    "        \"scarcity_months\": scarcity_months\n",
    "    })\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('water_scarcity.csv')\n",
    "\n",
    "@app.route('/get_graphs', methods=['POST'])\n",
    "def get_graphs():\n",
    "    # Get user inputs from JSON payload\n",
    "    data = request.get_json()\n",
    "    state = data.get('state')\n",
    "    district = data.get('district')\n",
    "\n",
    "    if not state or not district:\n",
    "        return jsonify({'error': 'Please provide both state and district'}), 400\n",
    "\n",
    "    # Filter the dataset by state and district\n",
    "    filtered_df = df[(df['State'] == state) & (df['District'] == district)]\n",
    "\n",
    "    # Get the last two months from today's date\n",
    "    end_date = datetime.today()\n",
    "    start_date = end_date - timedelta(days=60)  # Last 2 months\n",
    "\n",
    "    # Convert 'Date' to datetime type\n",
    "    filtered_df['Date'] = pd.to_datetime(filtered_df['Date'])\n",
    "\n",
    "    # Filter data for the last 2 months\n",
    "    recent_data = filtered_df[filtered_df['Date'] >= start_date]\n",
    "\n",
    "    if recent_data.empty:\n",
    "        return jsonify({'error': 'No data found for the given state and district for the last 2 months'}), 404\n",
    "\n",
    "    # Initialize list to store image files\n",
    "    img_files = []\n",
    "\n",
    "    # Plot graphs for each parameter\n",
    "    parameters = ['Rainfall (mm)', 'Groundwater Level (m)', 'Temperature (°C)', 'River Water Level (m)']\n",
    "    for param in parameters:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(recent_data['Date'], recent_data[param], marker='o', linestyle='-', color='b')\n",
    "        plt.title(f'{param} over Last 2 Months')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel(param)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Save plot to a BytesIO object\n",
    "        img = io.BytesIO()\n",
    "        plt.savefig(img, format='png')\n",
    "        img.seek(0)\n",
    "        img_files.append(img)\n",
    "        plt.close()\n",
    "\n",
    "    # Return all images as a zip file\n",
    "    from zipfile import ZipFile\n",
    "    import os\n",
    "\n",
    "    # Create a temporary folder to store images\n",
    "    temp_folder = 'temp_images'\n",
    "    os.makedirs(temp_folder, exist_ok=True)\n",
    "\n",
    "    # Save the images to files in the temporary folder\n",
    "    img_paths = []\n",
    "    for idx, img in enumerate(img_files):\n",
    "        img_path = os.path.join(temp_folder, f'graph_{idx+1}.png')\n",
    "        with open(img_path, 'wb') as f:\n",
    "            f.write(img.getvalue())\n",
    "        img_paths.append(img_path)\n",
    "\n",
    "    # Create a zip file containing the images\n",
    "    zip_filename = 'graphs.zip'\n",
    "    with ZipFile(zip_filename, 'w') as zipf:\n",
    "        for img_path in img_paths:\n",
    "            zipf.write(img_path, os.path.basename(img_path))\n",
    "\n",
    "    # Cleanup: remove the temporary image files\n",
    "    for img_path in img_paths:\n",
    "        os.remove(img_path)\n",
    "    os.rmdir(temp_folder)\n",
    "\n",
    "    # Send the zip file as a response\n",
    "    return send_file(zip_filename, mimetype='application/zip', as_attachment=True, download_name='graphs.zip')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d7ff53-8060-43b0-8f9c-1bfb8285d46c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3777e8f1-34a9-42cc-b131-97df6d8fcfbd",
   "metadata": {},
   "source": [
    "**API for separate Scarcity and timing prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9e8b3f2-b841-4ca4-83e5-9d90353479a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "C:\\Users\\Manju\\AppData\\Local\\Temp\\ipykernel_29644\\1192095360.py:141: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['Date'] = pd.to_datetime(filtered_df['Date'])\n",
      "127.0.0.1 - - [01/Feb/2025 18:22:16] \"POST /get_graphs HTTP/1.1\" 200 -\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [01/Feb/2025 18:22:29] \"POST /predict_timing HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [01/Feb/2025 18:22:29] \"POST /predict_timing HTTP/1.1\" 200 -\n",
      "C:\\Users\\Manju\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Manju\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "127.0.0.1 - - [01/Feb/2025 18:22:36] \"POST /predict_scarcity HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [01/Feb/2025 18:22:36] \"POST /predict_scarcity HTTP/1.1\" 200 -\n",
      "C:\\Users\\Manju\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\Manju\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "127.0.0.1 - - [01/Feb/2025 18:22:44] \"POST /predict_scarcity HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [01/Feb/2025 18:22:44] \"POST /predict_scarcity HTTP/1.1\" 200 -\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [01/Feb/2025 18:23:10] \"POST /predict_timing HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [01/Feb/2025 18:23:10] \"POST /predict_timing HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from flask import Flask, request, jsonify,send_file\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load saved models\n",
    "with open(\"scarcity_classifier.pkl\", \"rb\") as f:\n",
    "    rf_model = pickle.load(f)\n",
    "\n",
    "with open(\"label_encoders.pkl\", \"rb\") as f:\n",
    "    label_encoders = pickle.load(f)\n",
    "\n",
    "with open(\"scaler.pkl\", \"rb\") as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "# Features used for predictions\n",
    "features = [\"Rainfall (mm)\", \"Groundwater Level (m)\", \"Temperature (°C)\", \"River Water Level (m)\"]\n",
    "target_col = \"Scarcity\"\n",
    "\n",
    "# Function to map forecast to month\n",
    "def map_forecast_to_month(scarcity_forecast):\n",
    "    if scarcity_forecast < 0.2:\n",
    "        return \"No immediate scarcity, expected in 12+ months\"\n",
    "    elif 0.2 <= scarcity_forecast < 0.5:\n",
    "        return \"Scarcity expected in 6–12 months\"\n",
    "    elif 0.5 <= scarcity_forecast < 0.8:\n",
    "        return \"Scarcity expected in 3–6 months\"\n",
    "    elif scarcity_forecast >= 0.8:\n",
    "        return \"Scarcity expected within the next 3 months\"\n",
    "    else:\n",
    "        return \"Invalid forecast value\"\n",
    "\n",
    "# Function to create sequences for LSTM model\n",
    "def create_lstm_sequence(data, n_steps=6):\n",
    "    seq = []\n",
    "    for i in range(n_steps):\n",
    "        seq.append(data.iloc[i][features + [target_col]].values)\n",
    "    return np.array([seq])\n",
    "\n",
    "# Endpoint for scarcity classification\n",
    "@app.route(\"/predict_scarcity\", methods=[\"POST\"])\n",
    "def predict_scarcity():\n",
    "    try:\n",
    "        # Get JSON data from request\n",
    "        data = request.get_json()\n",
    "\n",
    "        # Extract features\n",
    "        input_data = np.array([[data[feature] for feature in features]])\n",
    "\n",
    "        # Scale input\n",
    "        input_data = scaler.transform(input_data)\n",
    "\n",
    "        # Predict with Random Forest model\n",
    "        prediction = rf_model.predict(input_data)[0]\n",
    "\n",
    "        return jsonify({\"scarcity_prediction\": int(prediction)})\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)})\n",
    "\n",
    "# Endpoint for scarcity timing prediction using LSTM\n",
    "@app.route(\"/predict_timing\", methods=[\"POST\"])\n",
    "def predict_timing():\n",
    "    try:\n",
    "        # Get JSON data\n",
    "        data = request.get_json()\n",
    "\n",
    "        # Extract state & district\n",
    "        state = data[\"State\"]\n",
    "        district = data[\"District\"]\n",
    "\n",
    "        # Encode state & district\n",
    "        if state in label_encoders[\"State\"].classes_ and district in label_encoders[\"District\"].classes_:\n",
    "            state_encoded = label_encoders[\"State\"].transform([state])[0]\n",
    "            district_encoded = label_encoders[\"District\"].transform([district])[0]\n",
    "        else:\n",
    "            return jsonify({\"error\": \"Invalid state or district\"})\n",
    "\n",
    "        # Load LSTM model for the state-district\n",
    "        model_path = f\"lstm_scarcity_{state}_{district}.h5\"\n",
    "        try:\n",
    "            lstm_model = load_model(model_path)\n",
    "        except:\n",
    "            return jsonify({\"error\": \"No LSTM model found for this location\"})\n",
    "\n",
    "        # Convert input data to a DataFrame (for consistency)\n",
    "        df_input = pd.DataFrame(data[\"historical_data\"])\n",
    "\n",
    "        # Scale numerical data\n",
    "        df_input[features] = scaler.transform(df_input[features])\n",
    "\n",
    "        # Generate sequence for LSTM model\n",
    "        X_input = create_lstm_sequence(df_input)\n",
    "\n",
    "        # Ensure shape matches model input\n",
    "        X_input = X_input.reshape(1, 6, len(features) + 1)  # Adjust shape if needed\n",
    "\n",
    "        # Predict scarcity timing using LSTM model\n",
    "        lstm_prediction = lstm_model.predict(X_input)[0][0]\n",
    "\n",
    "        # Map the scarcity forecast to months\n",
    "        forecast_month = map_forecast_to_month(lstm_prediction)\n",
    "\n",
    "        return jsonify({\n",
    "            \"scarcity_forecast\": float(lstm_prediction),\n",
    "            \"forecast_month\": forecast_month\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({\"error\": str(e)})\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('water_scarcity.csv')\n",
    "\n",
    "@app.route('/get_graphs', methods=['POST'])\n",
    "def get_graphs():\n",
    "    # Get user inputs from JSON payload\n",
    "    data = request.get_json()\n",
    "    state = data.get('state')\n",
    "    district = data.get('district')\n",
    "\n",
    "    if not state or not district:\n",
    "        return jsonify({'error': 'Please provide both state and district'}), 400\n",
    "\n",
    "    # Filter the dataset by state and district\n",
    "    filtered_df = df[(df['State'] == state) & (df['District'] == district)]\n",
    "\n",
    "    # Get the last two months from today's date\n",
    "    end_date = datetime.today()\n",
    "    start_date = end_date - timedelta(days=60)  # Last 2 months\n",
    "\n",
    "    # Convert 'Date' to datetime type\n",
    "    filtered_df['Date'] = pd.to_datetime(filtered_df['Date'])\n",
    "\n",
    "    # Filter data for the last 2 months\n",
    "    recent_data = filtered_df[filtered_df['Date'] >= start_date]\n",
    "\n",
    "    if recent_data.empty:\n",
    "        return jsonify({'error': 'No data found for the given state and district for the last 2 months'}), 404\n",
    "\n",
    "    # Initialize list to store image files\n",
    "    img_files = []\n",
    "\n",
    "    # Plot graphs for each parameter\n",
    "    parameters = ['Rainfall (mm)', 'Groundwater Level (m)', 'Temperature (°C)', 'River Water Level (m)']\n",
    "    for param in parameters:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(recent_data['Date'], recent_data[param], marker='o', linestyle='-', color='b')\n",
    "        plt.title(f'{param} over Last 2 Months')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel(param)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Save plot to a BytesIO object\n",
    "        img = io.BytesIO()\n",
    "        plt.savefig(img, format='png')\n",
    "        img.seek(0)\n",
    "        img_files.append(img)\n",
    "        plt.close()\n",
    "\n",
    "    # Return all images as a zip file\n",
    "    from zipfile import ZipFile\n",
    "    import os\n",
    "\n",
    "    # Create a temporary folder to store images\n",
    "    temp_folder = 'temp_images'\n",
    "    os.makedirs(temp_folder, exist_ok=True)\n",
    "\n",
    "    # Save the images to files in the temporary folder\n",
    "    img_paths = []\n",
    "    for idx, img in enumerate(img_files):\n",
    "        img_path = os.path.join(temp_folder, f'graph_{idx+1}.png')\n",
    "        with open(img_path, 'wb') as f:\n",
    "            f.write(img.getvalue())\n",
    "        img_paths.append(img_path)\n",
    "\n",
    "    # Create a zip file containing the images\n",
    "    zip_filename = 'graphs.zip'\n",
    "    with ZipFile(zip_filename, 'w') as zipf:\n",
    "        for img_path in img_paths:\n",
    "            zipf.write(img_path, os.path.basename(img_path))\n",
    "\n",
    "    # Cleanup: remove the temporary image files\n",
    "    for img_path in img_paths:\n",
    "        os.remove(img_path)\n",
    "    os.rmdir(temp_folder)\n",
    "\n",
    "    # Send the zip file as a response\n",
    "    return send_file(zip_filename, mimetype='application/zip', as_attachment=True, download_name='graphs.zip')\n",
    "\n",
    "# Run Flask app\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a2b684-d3d3-40b4-9d2e-3201c9b3f398",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
